---
layout: page
---

{{ content }}

<!-- role="list" needed so that `list-style: none` in Safari doesn't remove the list semantics -->
<style>
.truncate p {
    display: -webkit-box;
    -webkit-line-clamp: 5; /* number of lines to show */
    -webkit-box-orient: vertical;  
    overflow: hidden;
    margin:0px;
}

.expand p {
    white-space: normal;
    overflow: visible;
    margin:0px;
}

</style>

<script>
  function truncateText(selector, maxLength) {
    var element = document.querySelector(selector);
    var truncated = element.innerText;

    if (truncated.length > maxLength) {
        truncated = truncated.substr(0,maxLength) + '...';
    }
    element.innerText = truncated;
}


// Usage:
truncateText('#textBox p', 1000); // Truncate to 100 characters


function expandText() {
    var textBox = document.querySelector('#textBox');
    var link = textBox.querySelector('a');
    
    if (textBox.classList.contains('truncate')) {
      textBox.classList.remove('truncate');
      textBox.classList.add('expand');
      link.innerHTML = '<p style="margin-top:5px;color:grey;font-size:15px">(click to collapse)</p>';
    } else {
      textBox.classList.remove('expand');
      textBox.classList.add('truncate');
      link.innerHTML = '<p style="margin-top:5px;color:grey;font-size:15px">(click to expand)</p>';
    }
  }
</script>

<h1>Research</h1>
<div>
<a href="https://arxiv.org/abs/2311.07723"><h4>Generalization Analogies: a Testbed for Generalizing AI Oversight to Hard-To-Measure Domains</h4></a>
<div style="display:flex">
<a href="https://arxiv.org/abs/2311.07723"><p style="margin:0px; margin-right:10px">[Paper]</p></a>
<a href="https://twitter.com/joshua_clymer/status/1724851456967417872"><p style="margin:0px; margin-right:10px">[Tweet Thread]</p></a>
<a href="https://joshuaclymer.github.io/generalization-analogies-website/"><p style="margin:0px; margin-right:10px">[Browse Datasets]</p></a>
<a href="https://github.com/Joshuaclymer/GENIES"><p style="margin:0px; margin-right:10px">[Code]</p></a>
</div>
<div id="textBox" class="truncate">
  <p style="margin-top:10px;font-size:15px" onclick="expandText()">  As AI systems become more intelligent and their behavior becomes more challenging to assess, they may learn to game the flaws of human feedback instead of genuinely striving to follow instructions; however, this risk can be mitigated by controlling how LLMs generalize human feedback to situations where it is unreliable. To better understand how reward models generalize, we craft 69 distribution shifts spanning 8 categories. We find that reward models do not learn to evaluate `instruction-following' by default and instead favor personas that resemble internet text. Techniques for interpreting reward models' internal representations achieve better generalization than standard fine-tuning, but still frequently fail to distinguish instruction-following from conflated behaviors. We consolidate the 15 most challenging distribution shifts into the GENaralization analogIES (GENIES) benchmark, which we hope will enable progress toward controlling reward model generalization.</p>
  <a onclick="expandText()"><p style="margin-top:5px;color:grey;font-size:15px">(click to expand)</p></a>
</div>
</div>